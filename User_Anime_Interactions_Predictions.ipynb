{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "User-Anime Interactions Predictions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/nomomon/anime-recommendations/blob/master/User_Anime_Interactions_Predictions.ipynb",
      "authorship_tag": "ABX9TyOA7zGTUfQ1cQ642YrPfggg"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "PUNeUN_1JbAQ",
        "outputId": "1a5d8b45-de19-4451-b91b-2cd42e7c6533",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Kaggle API\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "username = str(input(\"username: \"))\n",
        "key = str(input(\"key: \"))\n",
        "\n",
        "clear_output()\n",
        "\n",
        "f = open(\"kaggle.json\", \"w\")\n",
        "f.write('{\"username\":\"'+username+'\",\"key\":\"'+key+'\"}')\n",
        "f.close()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle datasets download -d hernan4444/anime-recommendation-database-2020\n",
        "\n",
        "import os, re\n",
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/anime-recommendation-database-2020.zip', 'r') as zipObj:\n",
        "   zipObj.extractall()\n",
        "\n",
        "def purge(dir, pattern):\n",
        "    for f in os.listdir(dir):\n",
        "        if pattern in f:\n",
        "            os.remove(os.path.join(dir, f))\n",
        "\n",
        "purge(\"/content/\", \".zip\")\n",
        "purge(\"/content/\", \".json\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading anime-recommendation-database-2020.zip to /content\n",
            " 99% 651M/661M [00:05<00:00, 164MB/s]\n",
            "100% 661M/661M [00:05<00:00, 123MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knCcMBuxBqIq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMWiDA25J2ws"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyy-fObFKWIh"
      },
      "source": [
        "interactions = pd.read_csv(\"/content/animelist.csv\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwfKyqkV9PqT"
      },
      "source": [
        "Let's add a new feature `interaction`, which will be a 1 if the user had a positive interaction, 0.5 if we don't know, and 0 otherwise. We will model the interaction values using the `watching_status`.\n",
        "\n",
        "```\n",
        "1: Currently Watching\n",
        "2: Completed\n",
        "3: On Hold\n",
        "4: Dropped\n",
        "6: Plan to Watch\n",
        "```\n",
        "\n",
        "First, let's remove incorrect data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-d3gy4y9Pai"
      },
      "source": [
        "interactions = interactions[interactions[\"watching_status\"] <= 4]\n",
        "interactions = interactions[interactions[\"watching_status\"] >= 2]\n",
        "interactions = interactions[interactions[\"watching_status\"] != 3]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJmwT1_qC8RF"
      },
      "source": [
        "We'll model interactions using the following function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHSNuuYs-6UE"
      },
      "source": [
        "def transform(df):\n",
        "    df.loc[df[\"rating\"] <= 5, [\"watching_status\"]] = 0.0\n",
        "    df.loc[df[\"watching_status\"] == 2, [\"watching_status\"]] = 1.0\n",
        "    df.loc[df[\"watching_status\"] == 4, [\"watching_status\"]] = 0.0\n",
        "\n",
        "    df.rename(columns = {'watching_status': 'interaction'}, inplace = True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG4EdTmrOCfj"
      },
      "source": [
        "transform(interactions)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBZjvfBzLABg"
      },
      "source": [
        "good = interactions['user_id'].value_counts().loc[lambda x : x>4].unique()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEf1EOCKLyTB"
      },
      "source": [
        "interactions = interactions[interactions[\"user_id\"].isin(good)]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOesnn4tCHZy",
        "outputId": "89f4fc26-da2f-4ba8-b10c-f780bfc6dfb7"
      },
      "source": [
        "interactions[\"interaction\"].value_counts()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    365972\n",
              "0    143885\n",
              "Name: interaction, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDtMSZYSD2E9"
      },
      "source": [
        "interactions = interactions.drop(columns = [\"rating\", \"watched_episodes\"])\n",
        "interactions.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6O_FhTkPIv-",
        "outputId": "b0fc6645-9d51-4956-9668-c32bdcc5ca53"
      },
      "source": [
        "num_users = interactions[\"user_id\"].nunique()\n",
        "num_anime = interactions[\"anime_id\"].nunique()\n",
        "\n",
        "print(f\"There are a total of {num_users} users found.\")\n",
        "print(f\"There are a total of {num_anime} anime found.\")\n",
        "\n",
        "print(\"Max user id:\", interactions[\"user_id\"].max())\n",
        "print(\"Max anime id:\", interactions[\"anime_id\"].max())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are a total of 2365 users found.\n",
            "There are a total of 11663 anime found.\n",
            "Max user id: 16819\n",
            "Max anime id: 48456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFr1nQ7pK_4D"
      },
      "source": [
        "If we take a look at the anime and user ids, we can notice that some values there are missing. Let's make a two helper functions, for easy conversion between dataset ids and embedding ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdrHdPV3Ptql"
      },
      "source": [
        "embId2user = sorted(interactions[\"user_id\"].unique())\n",
        "embId2anime = sorted(interactions[\"anime_id\"].unique())"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJB-XaGCQysw"
      },
      "source": [
        "user2embId = {v: k for k, v in enumerate(embId2user)}\n",
        "anime2embId = {v: k for k, v in enumerate(embId2anime)}"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l15b5d46MbO8"
      },
      "source": [
        "Now, let's make the dataset. It will look like a tuples of `(user_id, anime_embId, rating)`. We'll make 3 sets: `train`, `test` and `val`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxPODUGFMflP"
      },
      "source": [
        "np.random.seed(seed = 42)\n",
        "\n",
        "def makeDataSet(df, split=0.95):\n",
        "    n = df.to_numpy()\n",
        "    \n",
        "    n = np.random.permutation(n)\n",
        "\n",
        "    x = n[:, :2]\n",
        "    y = n[:, 2]\n",
        "\n",
        "    for i in range(x.shape[0]):\n",
        "        x[i][0] = user2embId[x[i][0]]\n",
        "        x[i][1] = anime2embId[x[i][1]]\n",
        "\n",
        "    s1 = int(split * n.shape[0])\n",
        "    s2 = s1 + int((1 - split) * n.shape[0] / 10)\n",
        "    \n",
        "    return (x[:s1], y[:s1], x[s1:s2], y[s1:s2], x[s2:], y[s2:])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "302P1G-FSQw1"
      },
      "source": [
        "x_train, y_train, x_test, y_test, x_val, y_val = makeDataSet(interactions)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpbNLzFSceej"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOwjbc59J1Zk",
        "outputId": "1d109507-f12c-475e-8a1e-c501f33f6049"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vmn2iticyfh"
      },
      "source": [
        "## Matrix Factorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYgyxsiAx6lw"
      },
      "source": [
        "class MatrixFactorizationModel(tf.keras.Model):\n",
        "    def __init__(self, num_users, num_items, embedding_dim):\n",
        "        super(MatrixFactorizationModel, self).__init__()\n",
        "        \n",
        "        self.embedding_dim = embedding_dim\n",
        "        \n",
        "        self.user_embeddings = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
        "        self.item_embeddings = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
        "\n",
        "        self.user_biases = tf.keras.layers.Embedding(num_users, 1)\n",
        "        self.item_biases = tf.keras.layers.Embedding(num_items, 1)\n",
        "\n",
        "        self.bias = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(.5)\n",
        "\n",
        "    def call(self, inputs, training = False):\n",
        "        user_ids = inputs[:, 0]\n",
        "        item_ids = inputs[:, 1]\n",
        "\n",
        "        user_embedding = self.user_embeddings(user_ids) + self.user_biases(user_ids)\n",
        "        item_embedding = self.item_embeddings(item_ids) + self.item_biases(item_ids)\n",
        "\n",
        "        if training:\n",
        "            user_embedding = self.dropout(user_embedding, training = training)\n",
        "            item_embedding = self.dropout(item_embedding, training = training)\n",
        "\n",
        "        user_embedding = tf.reshape(user_embedding, [-1, self.embedding_dim])\n",
        "        item_embedding = tf.reshape(item_embedding, [-1, self.embedding_dim])\n",
        "\n",
        "        dot = tf.keras.layers.Dot(axes=1)([user_embedding, item_embedding]) + self.bias\n",
        "\n",
        "        return tf.math.sigmoid(dot)\n",
        "        \n",
        "    def plot_model(self, \n",
        "                   to_file = 'model.png', dpi = 96, \n",
        "                   show_shapes = True, \n",
        "                   show_layer_names = True, \n",
        "                   expand_nested = True):\n",
        "        x = tf.keras.layers.Input(shape=(2, 1))\n",
        "\n",
        "        return tf.keras.utils.plot_model(\n",
        "            tf.keras.Model(inputs=[x], outputs = self.call(x)),\n",
        "            to_file = to_file, \n",
        "            dpi = dpi,\n",
        "            show_shapes = show_shapes, \n",
        "            show_layer_names = show_layer_names,\n",
        "            expand_nested = expand_nested,\n",
        "            # rankdir = 'LR'  \n",
        "        )"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPVE4ep2GRFk"
      },
      "source": [
        "mf_model = MatrixFactorizationModel(num_users = num_users, \n",
        "                                    num_items = num_anime, \n",
        "                                    embedding_dim = 64)\n",
        "\n",
        "mf_model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics = [\n",
        "        tf.keras.metrics.BinaryAccuracy(\"Acc\"),\n",
        "        tf.keras.metrics.Precision(name = \"P\"),\n",
        "        tf.keras.metrics.Recall(name = \"R\")\n",
        "    ],\n",
        "    run_eagerly = True\n",
        ")"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9s2ZqTeJWJe",
        "outputId": "ce520c3b-2d64-49f8-8598-2a370144e93c"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3)\n",
        "\n",
        "history = mf_model.fit(\n",
        "    x = x_train, y = y_train,\n",
        "    class_weight = {\n",
        "        0: 2.5,\n",
        "        1: 1.\n",
        "    },\n",
        "    batch_size = 64, \n",
        "    epochs = 100, \n",
        "    steps_per_epoch = 1000,\n",
        "    callbacks = [callback],\n",
        "    validation_data = (x_test, y_test),\n",
        "    validation_steps = 10,\n",
        "    validation_batch_size = 64\n",
        ")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.9892 - Acc: 0.5313 - P: 0.7158 - R: 0.5744 - val_loss: 0.6886 - val_Acc: 0.5750 - val_P: 0.7338 - val_R: 0.6413\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 50s 50ms/step - loss: 0.9642 - Acc: 0.5844 - P: 0.7527 - R: 0.6286 - val_loss: 0.6032 - val_Acc: 0.6953 - val_P: 0.8208 - val_R: 0.7370\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.8156 - Acc: 0.7141 - P: 0.8501 - R: 0.7310 - val_loss: 0.4809 - val_Acc: 0.7453 - val_P: 0.8877 - val_R: 0.7391\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.7376 - Acc: 0.7450 - P: 0.8823 - R: 0.7452 - val_loss: 0.4679 - val_Acc: 0.7531 - val_P: 0.8892 - val_R: 0.7500\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.7266 - Acc: 0.7493 - P: 0.8856 - R: 0.7468 - val_loss: 0.4582 - val_Acc: 0.7625 - val_P: 0.9031 - val_R: 0.7500\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 49s 49ms/step - loss: 0.7102 - Acc: 0.7506 - P: 0.8931 - R: 0.7406 - val_loss: 0.4487 - val_Acc: 0.7703 - val_P: 0.8962 - val_R: 0.7696\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.7107 - Acc: 0.7538 - P: 0.8945 - R: 0.7463 - val_loss: 0.4356 - val_Acc: 0.7891 - val_P: 0.9114 - val_R: 0.7826\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.6952 - Acc: 0.7581 - P: 0.8970 - R: 0.7473 - val_loss: 0.4388 - val_Acc: 0.7750 - val_P: 0.9072 - val_R: 0.7652\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 47s 47ms/step - loss: 0.6846 - Acc: 0.7593 - P: 0.9002 - R: 0.7469 - val_loss: 0.4486 - val_Acc: 0.7609 - val_P: 0.9050 - val_R: 0.7457\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 47s 47ms/step - loss: 0.6968 - Acc: 0.7593 - P: 0.8997 - R: 0.7485 - val_loss: 0.4608 - val_Acc: 0.7688 - val_P: 0.9149 - val_R: 0.7478\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.7002 - Acc: 0.7598 - P: 0.9013 - R: 0.7475 - val_loss: 0.4454 - val_Acc: 0.7797 - val_P: 0.9121 - val_R: 0.7674\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 48s 48ms/step - loss: 0.7108 - Acc: 0.7540 - P: 0.8977 - R: 0.7403 - val_loss: 0.4461 - val_Acc: 0.7859 - val_P: 0.9130 - val_R: 0.7761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZe9Oke065gZ"
      },
      "source": [
        "mf_model.save_weights(\n",
        "    \"/content/drive/Shareddrives/ML/Anime RecSys/Interactions/MatrixFactorizationModel/model\", overwrite=True\n",
        ")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbVwQI4-Zq52",
        "outputId": "3a1afb98-db87-42dd-d75b-a8eb44f1c66f"
      },
      "source": [
        "mf_model.load_weights(\n",
        "    \"/content/drive/Shareddrives/ML/Anime RecSysInteractions/MatrixFactorizationModel/model\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0f504e6dd0>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAwYHMLee3hm"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2TEgnHvYjM6"
      },
      "source": [
        "class NeuralNetworkModel(tf.keras.Model):\n",
        "    def __init__(self, num_users, num_items, embedding_dim):\n",
        "        super(NeuralNetworkModel, self).__init__()\n",
        "        \n",
        "        self.embedding_dim = embedding_dim\n",
        "        \n",
        "        self.user_embeddings = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
        "        self.item_embeddings = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
        "\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "        self.concat = tf.keras.layers.Concatenate()\n",
        "        self.dropout = tf.keras.layers.Dropout(.5)\n",
        "\n",
        "    def call(self, inputs, training = False):\n",
        "        user_ids = inputs[:, 0]\n",
        "        item_ids = inputs[:, 1]\n",
        "\n",
        "        user_embedding = self.user_embeddings(user_ids)\n",
        "        item_embedding = self.item_embeddings(item_ids)\n",
        "\n",
        "        if training:\n",
        "            user_embedding = self.dropout(user_embedding, training = training)\n",
        "            item_embedding = self.dropout(item_embedding, training = training)\n",
        "\n",
        "        user_embedding = tf.reshape(user_embedding, [-1, self.embedding_dim])\n",
        "        item_embedding = tf.reshape(item_embedding, [-1, self.embedding_dim])\n",
        "\n",
        "        x = self.concat([user_embedding, item_embedding])\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def plot_model(self, \n",
        "                   to_file = 'model.png', dpi = 96, \n",
        "                   show_shapes = True, \n",
        "                   show_layer_names = True, \n",
        "                   expand_nested = True):\n",
        "        x = tf.keras.layers.Input(shape=(2, 1))\n",
        "\n",
        "        return tf.keras.utils.plot_model(\n",
        "            tf.keras.Model(inputs=[x], outputs = self.call(x)),\n",
        "            to_file = to_file, \n",
        "            dpi = dpi,\n",
        "            show_shapes = show_shapes, \n",
        "            show_layer_names = show_layer_names,\n",
        "            expand_nested = expand_nested,\n",
        "            # rankdir = 'LR'  \n",
        "        )"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z3Rx76ydbG-"
      },
      "source": [
        "nn_model = NeuralNetworkModel(num_users = num_users, \n",
        "                              num_items = num_anime, \n",
        "                              embedding_dim = 64)\n",
        "\n",
        "nn_model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics = [\n",
        "        tf.keras.metrics.BinaryAccuracy(\"Acc\"),\n",
        "        tf.keras.metrics.Precision(name = \"P\"),\n",
        "        tf.keras.metrics.Recall(name = \"R\")\n",
        "    ],\n",
        "    run_eagerly = True\n",
        ")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PDFoTbcdkoK",
        "outputId": "541f9dba-09b9-453d-d366-8d8b676808ec"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3)\n",
        "\n",
        "history = nn_model.fit(\n",
        "    x = x_train, y = y_train, \n",
        "    class_weight = {\n",
        "        0: 2.5,\n",
        "        1: 1.\n",
        "    },\n",
        "    batch_size = 64, \n",
        "    epochs = 100,\n",
        "    steps_per_epoch = 1000,\n",
        "    callbacks = [callback],\n",
        "    validation_data = (x_test, y_test),\n",
        "    validation_steps = 10,\n",
        "    validation_batch_size = 64\n",
        ")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7679 - Acc: 0.7510 - P: 0.8495 - R: 0.7943 - val_loss: 0.4471 - val_Acc: 0.8109 - val_P: 0.8742 - val_R: 0.8609\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6865 - Acc: 0.7789 - P: 0.8801 - R: 0.8000 - val_loss: 0.4493 - val_Acc: 0.7969 - val_P: 0.9064 - val_R: 0.8000\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6649 - Acc: 0.7818 - P: 0.8875 - R: 0.7977 - val_loss: 0.4300 - val_Acc: 0.8078 - val_P: 0.8874 - val_R: 0.8391\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6512 - Acc: 0.7885 - P: 0.8925 - R: 0.8021 - val_loss: 0.4303 - val_Acc: 0.8156 - val_P: 0.9150 - val_R: 0.8196\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6461 - Acc: 0.7893 - P: 0.8925 - R: 0.8036 - val_loss: 0.4243 - val_Acc: 0.8156 - val_P: 0.9052 - val_R: 0.8304\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6385 - Acc: 0.7938 - P: 0.8937 - R: 0.8086 - val_loss: 0.4327 - val_Acc: 0.8062 - val_P: 0.9200 - val_R: 0.8000\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6409 - Acc: 0.7919 - P: 0.8943 - R: 0.8048 - val_loss: 0.4149 - val_Acc: 0.8266 - val_P: 0.9087 - val_R: 0.8435\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6256 - Acc: 0.7965 - P: 0.8976 - R: 0.8083 - val_loss: 0.4128 - val_Acc: 0.8266 - val_P: 0.9205 - val_R: 0.8304\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6119 - Acc: 0.8030 - P: 0.9024 - R: 0.8143 - val_loss: 0.4121 - val_Acc: 0.8203 - val_P: 0.9097 - val_R: 0.8326\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6194 - Acc: 0.8013 - P: 0.8995 - R: 0.8134 - val_loss: 0.4237 - val_Acc: 0.8234 - val_P: 0.9181 - val_R: 0.8283\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6212 - Acc: 0.8014 - P: 0.8974 - R: 0.8172 - val_loss: 0.4180 - val_Acc: 0.8203 - val_P: 0.9117 - val_R: 0.8304\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 0.6235 - Acc: 0.7979 - P: 0.8969 - R: 0.8115 - val_loss: 0.4185 - val_Acc: 0.8234 - val_P: 0.9221 - val_R: 0.8239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHZXZe9agMJz"
      },
      "source": [
        "nn_model.save_weights(\n",
        "    \"/content/drive/Shareddrives/ML/Anime RecSys/Interactions/NeuralNetworkModel/model\", overwrite=True\n",
        ")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "038DIWBigTxo",
        "outputId": "0f69ad64-9ee8-4af9-b25b-c4db8d9c3087"
      },
      "source": [
        "nn_model.load_weights(\n",
        "    \"/content/drive/Shareddrives/ML/Anime RecSys/Interactions/NeuralNetworkModel/model\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0f504d6210>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUdCmooRYjq4"
      },
      "source": [
        "## Comparing the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibd8k5TYJKc4",
        "outputId": "db37c7be-338e-4fbe-c1b2-9e48aa623d1c"
      },
      "source": [
        "mf_model.evaluate(x = x_val, y = y_val)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "717/717 [==============================] - 18s 26ms/step - loss: 0.4691 - Acc: 0.7678 - P: 0.8969 - R: 0.7621\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4691160321235657,\n",
              " 0.7678260207176208,\n",
              " 0.8968790173530579,\n",
              " 0.7621142864227295]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTxFvxrbYna3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18748cfe-ed32-483d-b124-9b6838b18fe7"
      },
      "source": [
        "nn_model.evaluate(x = x_val, y = y_val)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "717/717 [==============================] - 17s 24ms/step - loss: 0.4211 - Acc: 0.8050 - P: 0.8907 - R: 0.8282\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4211376905441284,\n",
              " 0.8049598932266235,\n",
              " 0.8906558156013489,\n",
              " 0.8282309770584106]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}