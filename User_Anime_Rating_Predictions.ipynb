{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "User-Anime Rating Predictions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/nomomon/anime-recommendations/blob/master/User_Anime_Rating_Predictions.ipynb",
      "authorship_tag": "ABX9TyPCiPaSBsU2sTaXPbkk0YUi"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUNeUN_1JbAQ",
        "cellView": "form"
      },
      "source": [
        "#@title Kaggle API\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "username = str(input(\"username: \"))\n",
        "key = str(input(\"key: \"))\n",
        "\n",
        "clear_output()\n",
        "\n",
        "f = open(\"kaggle.json\", \"w\")\n",
        "f.write('{\"username\":\"'+username+'\",\"key\":\"'+key+'\"}')\n",
        "f.close()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle datasets download -d hernan4444/anime-recommendation-database-2020\n",
        "\n",
        "import os, re\n",
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/anime-recommendation-database-2020.zip', 'r') as zipObj:\n",
        "   zipObj.extractall()\n",
        "\n",
        "def purge(dir, pattern):\n",
        "    for f in os.listdir(dir):\n",
        "        if pattern in f:\n",
        "            os.remove(os.path.join(dir, f))\n",
        "\n",
        "purge(\"/content/\", \".zip\")\n",
        "purge(\"/content/\", \".json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knCcMBuxBqIq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMWiDA25J2ws"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyy-fObFKWIh"
      },
      "source": [
        "ratings = pd.read_csv(\"/content/animelist.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDtMSZYSD2E9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5c2464f2-d0ab-45cd-f797-90fbb414bef6"
      },
      "source": [
        "ratings.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>anime_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>watching_status</th>\n",
              "      <th>watched_episodes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>6702</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>242</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>4898</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  anime_id  rating  watching_status  watched_episodes\n",
              "0        0        67       9                1                 1\n",
              "1        0      6702       7                1                 4\n",
              "2        0       242      10                1                 4\n",
              "3        0      4898       0                1                 1\n",
              "4        0        21      10                1                 0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OddKB3oyOOHL",
        "outputId": "ed29c843-7e1c-4948-abc3-3ae36c5a15c0"
      },
      "source": [
        "ratings[\"rating\"].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     46827035\n",
              "8     15422150\n",
              "7     14244633\n",
              "9     10235934\n",
              "6      7543377\n",
              "10     7144392\n",
              "5      4029645\n",
              "4      1845854\n",
              "3       905700\n",
              "2       545339\n",
              "1       480688\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PN9jN7WLVLs"
      },
      "source": [
        "In the dataset, if a person hasn't left a rating to an anime, it was marked as a zero. Let's remove the zeros, as they will just introduce noise later on. Might as well remove the `watching_status` and `watched_episodes`. They are usefull pieces of data, but we won't use them in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rfk98wcLJT_"
      },
      "source": [
        "ratings = ratings[ratings[\"rating\"] > 0]\n",
        "ratings = ratings.drop(columns = [\"watching_status\", \"watched_episodes\"])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6O_FhTkPIv-",
        "outputId": "3cf5f89a-c52b-4f82-d502-40cacff3d5bb"
      },
      "source": [
        "num_users = ratings[\"user_id\"].nunique()\n",
        "num_anime = ratings[\"anime_id\"].nunique()\n",
        "\n",
        "print(f\"There are a total of {num_users} users found.\")\n",
        "print(f\"There are a total of {num_anime} anime found.\")\n",
        "\n",
        "print(\"Max user id:\", ratings[\"user_id\"].max())\n",
        "print(\"Max anime id:\", ratings[\"anime_id\"].max())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are a total of 313670 users found.\n",
            "There are a total of 17172 anime found.\n",
            "Max user id: 353404\n",
            "Max anime id: 48456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFr1nQ7pK_4D"
      },
      "source": [
        "If we take a look at the anime and user ids, we can notice that some values there are missing. Let's make a two helper functions, for easy conversion between dataset ids and embedding ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdrHdPV3Ptql"
      },
      "source": [
        "embId2user = sorted(ratings[\"user_id\"].unique())\n",
        "embId2anime = sorted(ratings[\"anime_id\"].unique())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJB-XaGCQysw"
      },
      "source": [
        "user2embId = {v: k for k, v in enumerate(embId2user)}\n",
        "anime2embId = {v: k for k, v in enumerate(embId2anime)}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l15b5d46MbO8"
      },
      "source": [
        "Now, let's make the dataset. It will look like a tuples of `(user_id, anime_embId, rating)`. We'll make 3 sets: `train`, `test` and `val`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxPODUGFMflP"
      },
      "source": [
        "np.random.seed(seed = 42)\n",
        "\n",
        "def makeDataSet(df, split=0.95):\n",
        "    n = df.to_numpy()\n",
        "    \n",
        "    n = np.random.permutation(n)\n",
        "\n",
        "    x = n[:, :2]\n",
        "    y = n[:, 2]\n",
        "\n",
        "    for i in range(x.shape[0]):\n",
        "        x[i][0] = user2embId[x[i][0]]\n",
        "        x[i][1] = anime2embId[x[i][1]]\n",
        "\n",
        "    s1 = int(split * n.shape[0])\n",
        "    s2 = s1 + int((1 - split) * n.shape[0] / 10)\n",
        "    \n",
        "    return (x[:s1], y[:s1], x[s1:s2], y[s1:s2], x[s2:], y[s2:])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "302P1G-FSQw1"
      },
      "source": [
        "x_train, y_train, x_test, y_test, x_val, y_val = makeDataSet(ratings)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpbNLzFSceej"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOwjbc59J1Zk",
        "outputId": "cb9334a0-0e58-4047-c499-dc8139e6475d"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vmn2iticyfh"
      },
      "source": [
        "## Matrix Factorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYgyxsiAx6lw"
      },
      "source": [
        "class MatrixFactorizationModel(tf.keras.Model):\n",
        "    def __init__(self, num_users, num_items, embedding_dim):\n",
        "        super(MatrixFactorizationModel, self).__init__()\n",
        "        \n",
        "        self.embedding_dim = embedding_dim\n",
        "        \n",
        "        self.user_embeddings = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
        "        self.item_embeddings = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
        "\n",
        "        self.user_biases = tf.keras.layers.Embedding(num_users, 1)\n",
        "        self.item_biases = tf.keras.layers.Embedding(num_items, 1)\n",
        "\n",
        "        self.bias = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(.5)\n",
        "\n",
        "    def call(self, inputs, training = False):\n",
        "        user_ids = inputs[:, 0]\n",
        "        item_ids = inputs[:, 1]\n",
        "\n",
        "        user_embedding = self.user_embeddings(user_ids) + self.user_biases(user_ids)\n",
        "        item_embedding = self.item_embeddings(item_ids) + self.item_biases(item_ids)\n",
        "\n",
        "        if training:\n",
        "            user_embedding = self.dropout(user_embedding, training = training)\n",
        "            item_embedding = self.dropout(item_embedding, training = training)\n",
        "\n",
        "        user_embedding = tf.reshape(user_embedding, [-1, self.embedding_dim])\n",
        "        item_embedding = tf.reshape(item_embedding, [-1, self.embedding_dim])\n",
        "\n",
        "        dot = tf.keras.layers.Dot(axes=1)([user_embedding, item_embedding]) + self.bias\n",
        "\n",
        "        return dot\n",
        "    def plot_model(self, \n",
        "                   to_file = 'model.png', dpi = 96, \n",
        "                   show_shapes = True, \n",
        "                   show_layer_names = True, \n",
        "                   expand_nested = True):\n",
        "        x = tf.keras.layers.Input(shape=(2, 1))\n",
        "\n",
        "        return tf.keras.utils.plot_model(\n",
        "            tf.keras.Model(inputs=[x], outputs = self.call(x)),\n",
        "            to_file = to_file, \n",
        "            dpi = dpi,\n",
        "            show_shapes = show_shapes, \n",
        "            show_layer_names = show_layer_names,\n",
        "            expand_nested = expand_nested,\n",
        "            # rankdir = 'LR'  \n",
        "        )"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPVE4ep2GRFk"
      },
      "source": [
        "mf_model = MatrixFactorizationModel(num_users = num_users, \n",
        "                                    num_items = num_anime, \n",
        "                                    embedding_dim = 64)\n",
        "\n",
        "mf_model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    loss = tf.keras.losses.MeanSquaredError(),\n",
        "    metrics = [\n",
        "        tf.keras.metrics.RootMeanSquaredError(\"RMSE\")\n",
        "    ],\n",
        "    run_eagerly = True\n",
        ")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9s2ZqTeJWJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f16adc5-0d15-40a5-d9d0-2abff26b29e1"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3)\n",
        "\n",
        "history = mf_model.fit(x = x_train, y = y_train, \n",
        "                    batch_size = 64, \n",
        "                    epochs = 100, \n",
        "                    steps_per_epoch = 1000,\n",
        "                    callbacks = [callback],\n",
        "                    validation_data = (x_test, y_test),\n",
        "                    validation_steps = 10,\n",
        "                    validation_batch_size = 64\n",
        "                    )"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 40s 36ms/step - loss: 51.3878 - RMSE: 7.1685 - val_loss: 43.5188 - val_RMSE: 6.5969\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 39.2640 - RMSE: 6.2661 - val_loss: 32.6083 - val_RMSE: 5.7104\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 29.2908 - RMSE: 5.4121 - val_loss: 23.8823 - val_RMSE: 4.8870\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 21.2222 - RMSE: 4.6068 - val_loss: 16.9432 - val_RMSE: 4.1162\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 14.9957 - RMSE: 3.8724 - val_loss: 11.6709 - val_RMSE: 3.4163\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 10.2482 - RMSE: 3.2013 - val_loss: 7.8572 - val_RMSE: 2.8031\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 6.8801 - RMSE: 2.6230 - val_loss: 5.3622 - val_RMSE: 2.3156\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 4.8236 - RMSE: 2.1963 - val_loss: 3.8972 - val_RMSE: 1.9741\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 3.7033 - RMSE: 1.9244 - val_loss: 3.3155 - val_RMSE: 1.8209\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 3.2764 - RMSE: 1.8101 - val_loss: 3.1728 - val_RMSE: 1.7812\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.1376 - RMSE: 1.7713 - val_loss: 3.1838 - val_RMSE: 1.7843\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.1726 - RMSE: 1.7812 - val_loss: 3.1860 - val_RMSE: 1.7849\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.1718 - RMSE: 1.7810 - val_loss: 3.2161 - val_RMSE: 1.7934\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.1191 - RMSE: 1.7661 - val_loss: 3.2033 - val_RMSE: 1.7898\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.1373 - RMSE: 1.7712 - val_loss: 3.1660 - val_RMSE: 1.7793\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.1489 - RMSE: 1.7745 - val_loss: 3.1373 - val_RMSE: 1.7712\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.1032 - RMSE: 1.7616 - val_loss: 3.1537 - val_RMSE: 1.7759\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.0726 - RMSE: 1.7529 - val_loss: 3.2241 - val_RMSE: 1.7956\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.1144 - RMSE: 1.7648 - val_loss: 3.1496 - val_RMSE: 1.7747\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.0640 - RMSE: 1.7504 - val_loss: 3.1395 - val_RMSE: 1.7719\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.0568 - RMSE: 1.7484 - val_loss: 3.1379 - val_RMSE: 1.7714\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.0874 - RMSE: 1.7571 - val_loss: 3.1239 - val_RMSE: 1.7675\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.0544 - RMSE: 1.7477 - val_loss: 3.0331 - val_RMSE: 1.7416\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 3.0261 - RMSE: 1.7396 - val_loss: 3.0436 - val_RMSE: 1.7446\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.0316 - RMSE: 1.7411 - val_loss: 3.0798 - val_RMSE: 1.7549\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.0156 - RMSE: 1.7365 - val_loss: 3.0086 - val_RMSE: 1.7345\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.0078 - RMSE: 1.7343 - val_loss: 2.9960 - val_RMSE: 1.7309\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 2.9975 - RMSE: 1.7313 - val_loss: 2.9678 - val_RMSE: 1.7227\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 3.0067 - RMSE: 1.7340 - val_loss: 2.9687 - val_RMSE: 1.7230\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 2.9951 - RMSE: 1.7306 - val_loss: 2.9853 - val_RMSE: 1.7278\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 2.9775 - RMSE: 1.7255 - val_loss: 2.9758 - val_RMSE: 1.7251\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 2.9900 - RMSE: 1.7292 - val_loss: 2.9928 - val_RMSE: 1.7300\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 2.9668 - RMSE: 1.7224 - val_loss: 2.9717 - val_RMSE: 1.7239\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 2.9666 - RMSE: 1.7224 - val_loss: 2.9520 - val_RMSE: 1.7181\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 2.9183 - RMSE: 1.7083 - val_loss: 2.9433 - val_RMSE: 1.7156\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 2.9299 - RMSE: 1.7117 - val_loss: 2.9439 - val_RMSE: 1.7158\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 2.8912 - RMSE: 1.7004 - val_loss: 2.9344 - val_RMSE: 1.7130\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 2.9460 - RMSE: 1.7164 - val_loss: 2.9134 - val_RMSE: 1.7069\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 2.9076 - RMSE: 1.7052 - val_loss: 2.8974 - val_RMSE: 1.7022\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 2.9143 - RMSE: 1.7071 - val_loss: 2.9305 - val_RMSE: 1.7119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZe9Oke065gZ"
      },
      "source": [
        "# mf_model.save_weights(\n",
        "#    \"/content/drive/Shareddrives/ML/Anime RecSys/MatrixFactorizationModel/model\", overwrite=True\n",
        "# )"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbVwQI4-Zq52",
        "outputId": "af87e00b-27f4-457c-96b9-56e8ae0330bc"
      },
      "source": [
        "mf_model.load_weights(\n",
        "    \"/content/drive/Shareddrives/ML/Anime RecSys/MatrixFactorizationModel/model\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8394447f90>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAwYHMLee3hm"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2TEgnHvYjM6"
      },
      "source": [
        "class NeuralNetworkModel(tf.keras.Model):\n",
        "    def __init__(self, num_users, num_items, embedding_dim):\n",
        "        super(NeuralNetworkModel, self).__init__()\n",
        "        \n",
        "        self.embedding_dim = embedding_dim\n",
        "        \n",
        "        self.user_embeddings = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
        "        self.item_embeddings = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
        "\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1, activation='relu')\n",
        "\n",
        "        self.concat = tf.keras.layers.Concatenate()\n",
        "        self.dropout = tf.keras.layers.Dropout(.5)\n",
        "\n",
        "    def call(self, inputs, training = False):\n",
        "        user_ids = inputs[:, 0]\n",
        "        item_ids = inputs[:, 1]\n",
        "\n",
        "        user_embedding = self.user_embeddings(user_ids)\n",
        "        item_embedding = self.item_embeddings(item_ids)\n",
        "\n",
        "        if training:\n",
        "            user_embedding = self.dropout(user_embedding, training = training)\n",
        "            item_embedding = self.dropout(item_embedding, training = training)\n",
        "\n",
        "        user_embedding = tf.reshape(user_embedding, [-1, self.embedding_dim])\n",
        "        item_embedding = tf.reshape(item_embedding, [-1, self.embedding_dim])\n",
        "\n",
        "        x = self.concat([user_embedding, item_embedding])\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "\n",
        "        return x\n",
        "    def plot_model(self, \n",
        "                   to_file = 'model.png', dpi = 96, \n",
        "                   show_shapes = True, \n",
        "                   show_layer_names = True, \n",
        "                   expand_nested = True):\n",
        "        x = tf.keras.layers.Input(shape=(2, 1))\n",
        "\n",
        "        return tf.keras.utils.plot_model(\n",
        "            tf.keras.Model(inputs=[x], outputs = self.call(x)),\n",
        "            to_file = to_file, \n",
        "            dpi = dpi,\n",
        "            show_shapes = show_shapes, \n",
        "            show_layer_names = show_layer_names,\n",
        "            expand_nested = expand_nested,\n",
        "            # rankdir = 'LR'  \n",
        "        )"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z3Rx76ydbG-"
      },
      "source": [
        "nn_model = NeuralNetworkModel(num_users = num_users, \n",
        "                              num_items = num_anime, \n",
        "                              embedding_dim = 64)\n",
        "\n",
        "nn_model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    loss = tf.keras.losses.MeanSquaredError(),\n",
        "    metrics = [\n",
        "        tf.keras.metrics.RootMeanSquaredError(\"RMSE\")\n",
        "    ],\n",
        "    run_eagerly = True\n",
        ")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PDFoTbcdkoK",
        "outputId": "73906077-90dd-475d-abf9-856c359421c7"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3)\n",
        "\n",
        "history = nn_model.fit(x = x_train, y = y_train, \n",
        "                       batch_size = 64, \n",
        "                       epochs = 100, \n",
        "                       steps_per_epoch = 1000,\n",
        "                       callbacks = [callback],\n",
        "                       validation_data = (x_test, y_test),\n",
        "                       validation_steps = 10,\n",
        "                       validation_batch_size = 64\n",
        "                    )"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 31s 29ms/step - loss: 10.0091 - RMSE: 3.1637 - val_loss: 2.7234 - val_RMSE: 1.6503\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.6697 - RMSE: 1.6339 - val_loss: 2.5527 - val_RMSE: 1.5977\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.5479 - RMSE: 1.5962 - val_loss: 2.4375 - val_RMSE: 1.5612\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 2.4327 - RMSE: 1.5597 - val_loss: 2.3629 - val_RMSE: 1.5372\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.4151 - RMSE: 1.5541 - val_loss: 2.3518 - val_RMSE: 1.5336\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.3623 - RMSE: 1.5370 - val_loss: 2.3340 - val_RMSE: 1.5277\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 2.3262 - RMSE: 1.5252 - val_loss: 2.2111 - val_RMSE: 1.4870\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 2.3197 - RMSE: 1.5231 - val_loss: 2.2371 - val_RMSE: 1.4957\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 2.2600 - RMSE: 1.5033 - val_loss: 2.2486 - val_RMSE: 1.4995\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.2286 - RMSE: 1.4928 - val_loss: 2.2399 - val_RMSE: 1.4966\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.2021 - RMSE: 1.4840 - val_loss: 2.1161 - val_RMSE: 1.4547\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.2217 - RMSE: 1.4905 - val_loss: 2.0767 - val_RMSE: 1.4411\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 2.1771 - RMSE: 1.4755 - val_loss: 2.0636 - val_RMSE: 1.4365\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 2.1556 - RMSE: 1.4682 - val_loss: 2.1530 - val_RMSE: 1.4673\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 2.1379 - RMSE: 1.4622 - val_loss: 2.0867 - val_RMSE: 1.4445\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.1178 - RMSE: 1.4553 - val_loss: 2.0798 - val_RMSE: 1.4422\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 2.1194 - RMSE: 1.4558 - val_loss: 2.1269 - val_RMSE: 1.4584\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.1369 - RMSE: 1.4618 - val_loss: 2.0744 - val_RMSE: 1.4403\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.1094 - RMSE: 1.4524 - val_loss: 2.0782 - val_RMSE: 1.4416\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.0984 - RMSE: 1.4486 - val_loss: 2.0662 - val_RMSE: 1.4374\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.1067 - RMSE: 1.4515 - val_loss: 2.0705 - val_RMSE: 1.4389\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 2.0731 - RMSE: 1.4398 - val_loss: 2.0193 - val_RMSE: 1.4210\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 2.0449 - RMSE: 1.4300 - val_loss: 2.0088 - val_RMSE: 1.4173\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 2.0526 - RMSE: 1.4327 - val_loss: 2.0213 - val_RMSE: 1.4217\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.0749 - RMSE: 1.4405 - val_loss: 2.0259 - val_RMSE: 1.4233\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 2.0502 - RMSE: 1.4318 - val_loss: 1.9865 - val_RMSE: 1.4094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHZXZe9agMJz"
      },
      "source": [
        "# nn_model.save_weights(\n",
        "#    \"/content/drive/Shareddrives/ML/Anime RecSys/NeuralNetworkModel/model\", overwrite=True\n",
        "# )"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "038DIWBigTxo",
        "outputId": "26061914-b9da-460c-e623-035ba6eacb1b"
      },
      "source": [
        "nn_model.load_weights(\n",
        "    \"/content/drive/Shareddrives/ML/Anime RecSys/NeuralNetworkModel/model\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8347e4ebd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUdCmooRYjq4"
      },
      "source": [
        "## Comparing the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibd8k5TYJKc4",
        "outputId": "0d5b9219-3cc0-454b-d66e-8990ce3596d7"
      },
      "source": [
        "mf_model.evaluate(x = x_val, y = y_val)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87747/87747 [==============================] - 959s 11ms/step - loss: 2.8429 - RMSE: 1.6861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.842893600463867, 1.68608820438385]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTxFvxrbYna3",
        "outputId": "c3c2a75a-fd5e-46c7-8151-6a050705b049"
      },
      "source": [
        "nn_model.evaluate(x = x_val, y = y_val)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87747/87747 [==============================] - 858s 10ms/step - loss: 1.9897 - RMSE: 1.4105\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.9896513223648071, 1.4105499982833862]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}